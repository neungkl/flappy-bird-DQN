{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 1000\n",
    "GAMMA = 0.99\n",
    "\n",
    "EXPLORE_INIT = 1.0\n",
    "EXPLORE_FINAL = 0.01\n",
    "EXPLORE_FINAL_FRAME = 100000\n",
    "\n",
    "MEMORY_SIZE = 50000\n",
    "MEMORT_START_SIZE = 1000\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "ACTION_SIZE = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outer game area and normalize to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = image / 255\n",
    "    return image[34:194,0:160,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 160, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f36189f4470>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADktJREFUeJzt3X/sXXV9x/Hny9aiglIQ13QUbdXO\nhZltNA1j05lFNgVk1GWG1JiJ2oQsw02Gixb5Q/8xkbnpNNkwKGy4MJAhxGZDB+twZsmoAvIbkVpF\n2rTU3zg1YvW9P+6p3k/pl9J77rnf71efj+Sbe87nnHvP+577/b6+55x7c9+pKiRpv6fMdwGSFhZD\nQVLDUJDUMBQkNQwFSQ1DQVJjsFBIclqSB5JsT7J5qO1Imq4M8TmFJEuALwJ/AOwEPge8tqrum/rG\nJE3VUEcKJwPbq2pHVT0GXA1sGGhbkqZo6UCPezzw8Nj8TuC35lr5qGVPqWOf7uUNaUgPP/rjr1fV\ncw613lChcEhJzgXOBTjmaU/hrb/zrPkqRfqFcP6nvvXQk1lvqH/Pu4ATxuZXdWM/VVWXVtX6qlp/\n1LIMVIakwzVUKHwOWJtkTZJlwEZgy0DbkjRFg5w+VNW+JG8G/gNYAlxeVfcOsS1J0zXYNYWqugG4\nYajHlzQML/lLahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgK\nkhqGgqSGoSCpYShIahgKkhqGgqTGxKGQ5IQkNye5L8m9Sd7SjR+b5KYkD3a3x0yvXElD63OksA94\na1WdCJwCnJfkRGAzsLWq1gJbu3lJi8TEoVBVu6vq9m76u8D9jNrFbQCu6Fa7Anh13yIlzc5Urikk\nWQ2cBGwDVlTV7m7RHmDFHPc5N8mtSW79v8em3/la0mR6h0KSo4CPA+dX1aPjy2rU5/6gf/G2jZMW\npl6hkOSpjALhyqq6rht+JMnKbvlKYG+/EiXNUp93HwJcBtxfVe8bW7QFOKebPgf4xOTlSZq1Pm3j\nXgL8CXB3kju6sXcA7wGuSbIJeAg4u1+JkmZp4lCoqv8B5roYcOqkjytpfvmJRkkNQ0FSw1CQ1DAU\nJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSYxpf\n8b4kyeeT/Fs3vybJtiTbk3wsybL+ZUqalWkcKbyFUXeo/S4G3l9VLwS+BWyawjYkzUjfvg+rgFcB\nH+nmA7wcuLZbxbZx0iLT90jh74C3AT/p5p8NfLuq9nXzOxn1l3wc28ZJC1OfZjBnAnur6rZJ7m/b\nOGlh6tsM5qwkZwBPA54FfABYnmRpd7SwCtjVv0xJs9KnFf2FVbWqqlYDG4H/qqrXATcDr+lWs22c\ntMgM8TmFtwMXJNnO6BrDZQNsQ9JA+pw+/FRVfRr4dDe9Azh5Go8rafb8RKOkhqEgqWEoSGoYCpIa\nhoKkhqEgqWEoSGoYCpIahoKkhqEgqWEoSGoYCpIahoKkhqEgqWEoSGoYCpIahoKkhqEgqdG3Gczy\nJNcm+UKS+5P8dpJjk9yU5MHu9phpFStpeH2PFD4AfKqqfhX4DUbt4zYDW6tqLbC1m5e0SPRpBnM0\n8DK6b2uuqseq6tvABkbt4sC2cdKi0+dIYQ3wNeAfu67TH0lyJLCiqnZ36+wBVvQtUtLs9AmFpcA6\n4JKqOgn4HgecKlRVAQdtFGkvSWlh6hMKO4GdVbWtm7+WUUg8kmQlQHe792B3tpektDD1aRu3B3g4\nyYu6oVOB+4AtjNrFgW3jpEWnb4eoPweuTLIM2AG8kVHQXJNkE/AQcHbPbUiaoV6hUFV3AOsPsujU\nPo8r/aK49YJXPW5s/fv+fR4q+Rk/0SipYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShI\nahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIavRtG/eXSe5Nck+Sq5I8LcmaJNuSbE/yse77\nGyUtEn06RB0P/AWwvqpeDCwBNgIXA++vqhcC3wI2TaNQSbPR9/RhKfD0JEuBZwC7gZcz6gEBto2T\nFp2Jv825qnYl+Rvgq8APgBuB24BvV9W+brWdwPG9q5R+Ts33NzcfTJ/Th2MYNZNdA/wycCRw2mHc\n37Zx0gLU5/Th94EvV9XXqupHwHXAS4Dl3ekEwCpg18HubNs4aWHqEwpfBU5J8owk4Wdt424GXtOt\nY9s4aZHp00tyG6MLircDd3ePdSnwduCCJNuBZwOXTaFOSTPSt23cO4F3HjC8Azi5z+NKmj9+olFS\nw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkN\nQ0FSw1CQ1DhkKCS5PMneJPeMjR2b5KYkD3a3x3TjSfLBrmXcXUnWDVm8pOl7MkcK/8Tj+zlsBrZW\n1VpgazcPcDqwtvs5F7hkOmVKmpVDhkJVfQb45gHDGxi1hIO2NdwG4KM1cgujHhArp1WspOFNek1h\nRVXt7qb3ACu66eOBh8fWs22ctMj0vtBYVQUcdt8328ZJC9OkofDI/tOC7nZvN74LOGFsPdvGSYvM\npKGwhVFLOGhbw20BXt+9C3EK8J2x0wxJi8AhO0QluQr4PeC4JDsZdYR6D3BNkk3AQ8DZ3eo3AGcA\n24HvA28coGZJAzpkKFTVa+dYdOpB1i3gvL5FSZo/fqJRUsNQkNQwFCQ1DAVJDUNBUsNQkNQwFCQ1\nDAVJDUNBUsNQkNQwFCQ1DAVJDUNBUsNQkNQwFCQ1DAVJDUNBUsNQkNSYtG3ce5N8oWsNd32S5WPL\nLuzaxj2Q5JVDFS5pGJO2jbsJeHFV/TrwReBCgCQnAhuBX+vu8w9JlkytWkmDm6htXFXdWFX7utlb\nGPV3gFHbuKur6odV9WVG3+p88hTrlTSwaVxTeBPwyW7atnHSItcrFJJcBOwDrpzgvraNkxagQ/Z9\nmEuSNwBnAqd2/R7gMNvGAZcCPPfopaaCtEBMdKSQ5DTgbcBZVfX9sUVbgI1JjkiyBlgLfLZ/mZJm\nZdK2cRcCRwA3JQG4par+tKruTXINcB+j04rzqurHQxUvafombRt32ROs/27g3X2KkjR//ESjpIah\nIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaC\npIahIKlhKEhqTNRLcmzZW5NUkuO6+ST5YNdL8q4k64YoWtJwJu0lSZITgFcAXx0bPp3R17qvBc4F\nLulfoqRZmqiXZOf9jHo/jDdy2QB8tEZuAZYnWTmVSiXNxKTNYDYAu6rqzgMWPelekraNkxamw24b\nl+QZwDsYnTpMzLZx0sI0SS/JFwBrgDu77lCrgNuTnMxh9JKUtDAd9ulDVd1dVb9UVaurajWjU4R1\nVbWHUS/J13fvQpwCfKeqdk+3ZElDejJvSV4F/C/woiQ7k2x6gtVvAHYA24EPA382lSolzcykvSTH\nl68emy7gvP5lSZovfqJRUsNQkNQwFCQ1DAVJDUNBUsNQkNQwFCQ1DAVJDUNBUsNQkNQwFCQ1DAVJ\nDUNBUsNQkNQwFCQ1DAVJDUNBUsNQkNQwFCQ1DAVJDUNBUiOjL2Ce5yKSrwHfA74+37UAx2Ed46yj\ntZjreF5VPedQKy2IUABIcmtVrbcO67CO+a3D0wdJDUNBUmMhhcKl811Axzpa1tH6ua9jwVxTkLQw\nLKQjBUkLwLyHQpLTkjyQZHuSzTPc7glJbk5yX5J7k7ylG39Xkl1J7uh+zphBLV9Jcne3vVu7sWOT\n3JTkwe72mIFreNHYc74jyaNJzp/F/khyeZK9Se4ZGzvo88/IB7vfl7uSrBu4jvcm+UK3reuTLO/G\nVyf5wdh++dDAdcz5OiS5sNsfDyR5Ze8CqmrefoAlwJeA5wPLgDuBE2e07ZXAum76mcAXgROBdwF/\nNeP98BXguAPG/hrY3E1vBi6e8euyB3jeLPYH8DJgHXDPoZ4/cAbwSSDAKcC2get4BbC0m754rI7V\n4+vNYH8c9HXofmfvBI4A1nR/T0v6bH++jxROBrZX1Y6qegy4Gtgwiw1X1e6qur2b/i5wP3D8LLb9\nJG0AruimrwBePcNtnwp8qaoemsXGquozwDcPGJ7r+W8APlojtwDLk6wcqo6qurGq9nWztwCrprGt\nw63jCWwArq6qH1bVl4HtjP6uJjbfoXA88PDY/E7m4Q8zyWrgJGBbN/Tm7nDx8qEP2zsF3JjktiTn\ndmMrqmp3N70HWDGDOvbbCFw1Nj/r/QFzP//5/J15E6OjlP3WJPl8kv9O8rsz2P7BXoep74/5DoV5\nl+Qo4OPA+VX1KHAJ8ALgN4HdwN/OoIyXVtU64HTgvCQvG19Yo+PEmbxNlGQZcBbwr93QfOyPxiyf\n/1ySXATsA67shnYDz62qk4ALgH9J8qwBS5jZ6zDfobALOGFsflU3NhNJnsooEK6squsAquqRqvpx\nVf0E+DA9D8WejKra1d3uBa7vtvnI/sPi7nbv0HV0Tgdur6pHuppmvj86cz3/mf/OJHkDcCbwui6g\n6A7Xv9FN38boXP5XhqrhCV6Hqe+P+Q6FzwFrk6zp/kNtBLbMYsNJAlwG3F9V7xsbHz8//SPgngPv\nO+U6jkzyzP3TjC5s3cNoP5zTrXYO8Ikh6xjzWsZOHWa9P8bM9fy3AK/v3oU4BfjO2GnG1CU5DXgb\ncFZVfX9s/DlJlnTTzwfWAjsGrGOu12ELsDHJEUnWdHV8ttfGhrh6ephXWs9gdOX/S8BFM9zuSxkd\nkt4F3NH9nAH8M3B3N74FWDlwHc9ndPX4TuDe/fsAeDawFXgQ+E/g2BnskyOBbwBHj40Nvj8YhdBu\n4EeMzok3zfX8Gb3r8Pfd78vdwPqB69jO6Jx9/+/Ih7p1/7h7ve4Abgf+cOA65nwdgIu6/fEAcHrf\n7fuJRkmN+T59kLTAGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKnx/4Zl1PkoeXv0AAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3618b73630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# env.reset()\n",
    "# action = env.action_space.sample()\n",
    "# obs, reward, done, _ = env.step(action)\n",
    "\n",
    "# image = env.render(mode='rgb_array')\n",
    "# image = image[34:194,0:160,0:3]\n",
    "# image = image / 255\n",
    "# print(image.shape)\n",
    "\n",
    "# plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork:\n",
    "    def __init__(self, learning_rate=0.001):\n",
    "        self.model = Sequential()\n",
    "\n",
    "        self.model.add(Dense(hidden_size, activation='relu',\n",
    "                             input_dim=state_size))\n",
    "        self.model.add(Dense(action_size, activation='linear'))\n",
    "\n",
    "        self.optimizer = Adam(lr=learning_rate)\n",
    "        self.model.compile(loss='mse', optimizer=self.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(\n",
    "            np.arange(len(self.buffer)),\n",
    "            size=batch_size,\n",
    "            replace=False\n",
    "        )\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(max_size = MEMORY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_rate = EXPLORE_INIT\n",
    "frame = 0\n",
    "\n",
    "for ep in range(0, EPISODES):\n",
    "    env.reset()\n",
    "    state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    state = preprocess(state)\n",
    "    frame += 1\n",
    "    \n",
    "    total_reward = 0\n",
    "    \n",
    "    while True:\n",
    "        explore_rate = np.max(\n",
    "            EXPLORE_FINAL, \n",
    "            EXPLORE_INIT - (EXPLORE_INIT - EXPLORE_FINAL) * frame / EXPLORE_FINAL_FRAME\n",
    "        )\n",
    "        \n",
    "        if np.random.rand() > explore_rate:\n",
    "            action = np.argmax(model.predict(state)[0])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "        \n",
    "        next_state, reward, done, _ = env.step(env.action_space.sample())\n",
    "        next_state = preprocess(next_state)\n",
    "        frame += 1\n",
    "        state = next_state\n",
    "        \n",
    "#         env.render()\n",
    "        \n",
    "        total_reward += reward\n",
    "        \n",
    "        memory.add((state, action, reward, done, next_state))\n",
    "        \n",
    "        if memory.size() >= MEMORT_START_SIZE:\n",
    "            minibatch = memory.sample(BATCH_SIZE)\n",
    "            \n",
    "            inputs = np.zeros((BATCH_SIZE, 160, 160, 3))\n",
    "            targets = np.zeros((BATCH_SIZE, ACTION_SIZE))\n",
    "            \n",
    "            for i, (state_b, action_b, reward_b, done_b, next_state_b) in enumerate(minibatch):\n",
    "                inputs[i:i+1] = state_b\n",
    "                if done_b:\n",
    "                    target = reward_b\n",
    "                else:\n",
    "                    target = reward_b + GAMMA * np.amax(model.predict(next_state_b)[0])\n",
    "                targets[i] = model.predict(state_b)\n",
    "                targets[i][action_b] = target\n",
    "                \n",
    "            model.fit(inputs, targets, epochs=1, verbose=0)\n",
    "\n",
    "        \n",
    "        if done:\n",
    "            print(\"Episode {}, Total Reward {}, Explore Rate {}\".format(ep + 1, total_reward, explore_rate))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
